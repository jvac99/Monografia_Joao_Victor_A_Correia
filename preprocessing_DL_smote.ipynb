{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Carregando as importações"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-09T20:13:51.378101Z","iopub.status.busy":"2023-04-09T20:13:51.377709Z","iopub.status.idle":"2023-04-09T20:13:56.764780Z","shell.execute_reply":"2023-04-09T20:13:56.763351Z","shell.execute_reply.started":"2023-04-09T20:13:51.378016Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from c:\\Users\\joao.correia\\Documents\\Faculdade\\Monografia_Joao_Victor_A_Correia\\imports\\imports_common_preprocessing.ipynb\n","importing Jupyter notebook from load_dataset.ipynb\n","importing Jupyter notebook from c:\\Users\\joao.correia\\Documents\\Faculdade\\Monografia_Joao_Victor_A_Correia\\imports\\imports_common.ipynb\n"]}],"source":["import import_ipynb\n","from imports.imports_common_preprocessing import *\n","from load_dataset import *\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.utils import to_categorical\n","# Aplicar aumento de dados (exemplo com a biblioteca imgaug)\n","import imgaug.augmenters as iaa"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'resize_image' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size \u001b[39m=\u001b[39m TEST_SIZE, random_state \u001b[39m=\u001b[39m SEED)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Redimensionar as imagens para um tamanho uniforme\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([resize_image(img) \u001b[39mfor\u001b[39;49;00m img \u001b[39min\u001b[39;49;00m X_train])\n\u001b[0;32m      6\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([resize_image(img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m X_test])\n\u001b[0;32m      8\u001b[0m \u001b[39m# Normaliza os valores de pixel para que estejam entre 0 e 1\u001b[39;00m\n","Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size \u001b[39m=\u001b[39m TEST_SIZE, random_state \u001b[39m=\u001b[39m SEED)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Redimensionar as imagens para um tamanho uniforme\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([resize_image(img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m X_train])\n\u001b[0;32m      6\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([resize_image(img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m X_test])\n\u001b[0;32m      8\u001b[0m \u001b[39m# Normaliza os valores de pixel para que estejam entre 0 e 1\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'resize_image' is not defined"]}],"source":["# Dividir os dados em conjuntos de treinamento e teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = SEED)\n","\n","# Redimensionar as imagens para um tamanho uniforme\n","X_train = np.array([resize_image(img) for img in X_train])\n","X_test = np.array([resize_image(img) for img in X_test])\n","\n","# Normaliza os valores de pixel para que estejam entre 0 e 1\n","X_train = np.array(X_train) / 255.0\n","X_test = np.array(X_test) / 255.0\n","\n","# Converte os rótulos em valores numéricos usando LabelEncoder\n","label_encoder = LabelEncoder()\n","y_train = label_encoder.fit_transform(y_train)\n","y_test = label_encoder.transform(y_test)\n","\n","# Codificar os rótulos usando one-hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","\n","augmentation = iaa.Sequential([\n","    iaa.Flipud(0.5),  # Espelhar verticalmente\n","    iaa.Affine(rotate=(-10, 10)),  # Rotação aleatória\n","    iaa.GaussianBlur(sigma=(0, 1.0))  # Desfoque gaussiano\n","])\n","\n","X_train = augmentation.augment_images(X_train)\n","\n","# Concatenar as imagens aumentadas com as originais\n","X_train = np.concatenate((X_train, X_train_augmented), axis=0)\n","y_train = np.concatenate((y_train, y_train), axis=0)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = TEST_SIZE, random_state = SEED)\n","\n","validation_data = (X_val, y_val)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
